<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Readme</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="../blog.css" />
  <script src="../code/es5/tex-chtml.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <link rel="stylesheet" href="/code/bootstrap.min.css">
  <script src="/code/jquery.min.js"></script>
  <script src="/code/bootstrap.min.js"></script>
  
  
  <ul class="bar">
    <li class="barli"><a class="active" href="/">Home</a></li>
    <li class="barli"><a href="/differentialprivacy/index.html">Notes on Differential Privacy</a></li>  
    <!-- <li class="barli"><a href="https://abiswas3.github.io/differentialprivacy.github.io">Notes on Differential Privacy</a></li> -->
  </ul>
</head>
<body>

<div class="container">
<p>Draft (first update): Novmber 2nd, 2021, 10:04 BST</p>
<p>Draft (last update): Novmber 18th, 2021. 14:24 BST</p>
<h1 id="algorithms-for-binary-sums-while-ensuring-differential-privacy">Algorithms for Binary Sums while ensuring Differential Privacy</h1>
<h2 id="the-problem-binary-sums">The problem – Binary Sums</h2>
<p>Each member of the dataset <span class="math inline">\(x \in D\)</span> holds a value in <span class="math inline">\(\{0, 1\}\)</span>. We simply want to estimate <span class="math inline">\(f(X) = \sum_{i=1}^n x_i\)</span>. Let <span class="math inline">\(\hat{f}(X)\)</span> be the estimated sum by the algorithms. Understanding binary sum gives us all the key insights we need to anslyse integer sums. In this writeup we consider the view of the anlyser for the three regimes in consideration. <strong>NOTE:</strong> this is purely for the sake of analysis. In practice they are usually implemented in a federated setting or local/shuffle privacy setting. The noise addition, thresholding and sampling might be done at the user level. We perform all the computations at the analyser level as it simplifies the analysis.</p>
<h2 id="the-2-different-regimes">The 2 different regimes</h2>
<p>Even though there are other algorithms quoted in the literature. We will show later in this document that analysing just two algorithms is sufficient to understand when to use which algorithm.</p>
<div class="row">
<div class="col-md-6">
<h3 id="simplified-additive-noise">Simplified Additive noise</h3>
</div>
<div class="col-md-6">
<h3 id="sample-and-threshold">Sample and Threshold</h3>
</div>
</div>
<h2 id="the-game-we-are-playing-which-algorithm-should-i-use">The game we are playing – Which algorithm should I use</h2>
<p>Say company “A” needs an estimate of a binary sum – and they need to do it privately. They do not understand statistics. All they have is a privacy budget described by <span class="math inline">\((\epsilon, \delta)\)</span>. Given this budget, they want the most accurate estimate possible. As consultants for this company how should we proceed.</p>
<div class="row">
<div class="col-md-6">
<h3 id="additive-binomial-noise-no-thresholding">Additive Binomial noise (no thresholding)</h3>
<p>Given an <span class="math inline">\((\epsilon, \delta)\)</span>, this regime needs the number of users <span class="math inline">\(n\)</span> to be at least <span class="math inline">\(\frac{100}{\epsilon^2}\log(2/\delta)\)</span> or more. Setting <span class="math inline">\(n=\frac{100}{\epsilon^2}\log(2/\delta)\)</span>, gives us <span class="math inline">\(p=1/2\)</span> which is adds the most noise to the algorithm (variance of binomial maximal at p=1/2)</p>
<p>We look at practical values of <span class="math inline">\((\epsilon, \delta)\)</span> and observe how many users are truly needed to guarantee differential privacy.</p>
<p><img src="pngs/dependence.png" width="100%" height="100%"></img></p>
<p>Observe, even with epsilon as high as 0.5, to avoid bad events 95% of the time, we need at least 1000 users to get privacy. This also means that <span class="math inline">\(Z \sim Binomial(n,p)\)</span> is approximately equal to <span class="math inline">\(np\)</span> as we are under the large <span class="math inline">\(n\)</span> regime. We expect error to be very small (from the tail bounds of a binomial within <span class="math inline">\(\frac{1}{\sqrt{n}}\)</span>). A second thing to note is that the error of this regime is given by <span class="math inline">\(|np - Z|\)</span> where <span class="math inline">\(Z \sim Binomial(n,p)\)</span>. The number of 1’s in a users data k, does not show up in the formula for error at all. We empirically validate this in the plot below. There should be no correlation between error and fraction of 1’s in users data.</p>
<p><img src="pngs/errorBinomialWithK.png" width="100%" height="100%"></img></p>
<p>Since the error of this regime is not effected by <span class="math inline">\(k=\sum_{i=1}^n x_i\)</span>, <strong>an effective application of this algorithm is when we are in the large data setting: n is large, and the number of users with 1’s is sparse.</strong></p>
</div>
<div class="col-md-6">
<h3 id="sample-and-threshold-1">Sample and Threshold</h3>
<p>Given an <span class="math inline">\((\epsilon, \delta)\)</span>, this algorithm imposes some restrictions on <span class="math inline">\(m\)</span> and <span class="math inline">\(\tau\)</span>. To ensure privacy, it requires <span class="math inline">\(\tau \geq 3 + \log(1/\delta)\)</span> and <span class="math inline">\(m \leq \frac{\epsilon n}{\tau}\)</span>. The random coin has parameter <span class="math inline">\(p=\frac{m}{n}\)</span>. Intuitively, the bigger the value of m, the worse the privacy but better the accuracy. Given a <span class="math inline">\((\epsilon, \delta)\)</span>, the optimal thing in terms of accuracy would be to set <span class="math inline">\(m\)</span> equal to <span class="math inline">\(\frac{\epsilon n}{\tau}\)</span> where <span class="math inline">\(\tau=3 + \log(1/\delta)\)</span>, which is the smallest possile value for the parameter. The figure below looks at the distribution of the parameter value <span class="math inline">\(p\)</span> as we look at practical values of <span class="math inline">\((\epsilon, \delta)\)</span></p>
<p><img src="pngs/pDep.png" width="100%" height="100%"></img></p>
<p>If we require extreme privacy, really small <span class="math inline">\(\epsilon\)</span> we will need to sample less than <span class="math inline">\(1\%\)</span> of the data and apply thresholding. Furthermore, we never sample more than <span class="math inline">\(8\%\)</span> of the data. Note,the parameter <span class="math inline">\(p\)</span> is independent of <span class="math inline">\(n\)</span>. See below:</p>
<p><span class="math display">\[\begin{align*}
p &amp;= \frac{m}{n} \\
 &amp;= \frac{\epsilon}{\tau} \tag{1} \label{1}\\
\end{align*}\]</span></p>
<p><span class="math inline">\(\ref{1}:\)</span> since <span class="math inline">\(m=\frac{\epsilon n}{\tau}\)</span></p>
<p>The above analysis provides intuition about where we expect this algorithm to shine! Non sparse regimes in the non large data regime. If the data set is very sparse where <span class="math inline">\(k \leq tau\)</span>, we have no hope to begin with. <strong>NOTE: The additive noise mechanisms have no issue in this regime, provided <span class="math inline">\(n\)</span> is big enough.</strong> On the contrary, in this world, no matter how small <span class="math inline">\(n\)</span> is, as long as <span class="math inline">\(k\)</span> is big enough we need not worry about getting bad estimates under even small values of <span class="math inline">\(n\)</span>.</p>
<p><strong>The natural question is how sparse is too sparse. With the other algorithm there is deterministic formula for <span class="math inline">\(n\)</span> which tells us that with probability 1 - <span class="math inline">\(\delta\)</span> we get privacy</strong></p>
</div>
<h2 id="experiments">Experiments</h2>
<p>Here we show empirically that our analysis above is true. We design datasets that suit each algorithm.</p>
<ul>
<li>Dataset I : The dataset is not sparse but we are in the low user regime.</li>
<li>Dataset II : Extremely sparse data but large user base.</li>
<li>Dataset III : A regime where they are roughly equal – as seen in AI stats paper datasets.</li>
</ul>
<h3 id="the-experiments-in-the-ai-stats-paper-do-not-shine-light-on-the-strengths-of-this-algorithm">The experiments in the AI Stats paper do not shine light on the strengths of this algorithm</h3>
<h2 id="the-thresholding-in-the-cheu-paper-is-slightly-deceiving">The thresholding in the Cheu paper is slightly deceiving</h2>
</div>
<h3 id="dependence-on-epsilon-and-delta">Dependence on <span class="math inline">\(\epsilon\)</span> and <span class="math inline">\(\delta\)</span></h3>
<p>In this section we re-derive the main parts of both proofs and establish the connection between the two regimes. Both regimes guarantee pure privacy under <strong>a good event</strong>. Both regimes claim that privacy is preserved with probaility <span class="math inline">\(1 - \delta\)</span> – where <span class="math inline">\(\delta\)</span> (the likelihood of bad events) shrinks very quickly as <span class="math inline">\(n\)</span> grows. When we write “shuffle privacy needs” or “sample privacy needs”, what we mean is the presented analysis in the paper needs – not the algorithm itself. As shown above both algorithms are equivalent. To guarantee privacy, shuffle privacy needs event <span class="math inline">\(E_1\)</span> and sample-threshold needs event <span class="math inline">\(E_2\)</span>. Let these events occur with probability at least <span class="math inline">\(1 - \delta_1\)</span> and <span class="math inline">\(1 - \delta_2\)</span>. In this analysis we will derive shuffle privacy and then morph the sample privacy proof to show equivalence.</p>
<p>The version of chernoff bound for bernoulli’s both papers utilise is the following:</p>
<p>Let <span class="math inline">\(\delta \geq 0\)</span> and <span class="math inline">\(\mu=pn\)</span>,</p>
<p><span class="math display">\[\mathbb{P}[\sum_{i=1}^n X_i \geq (1 + \delta)\mu] \leq \Big( \frac{e^{\delta}}{(1 + \delta)^{(1 + \delta)}}\Big)^{\mu} \leq e^{-\frac{\delta^2\mu}{2 + \delta}}\]</span></p>
<div class="row">
<div class="col-md-6">
<h4 id="shuffle">Shuffle</h4>
<p>First we try and understand what the good event <span class="math inline">\(E_1\)</span> actually is. The lemma’s used in this section can be found in Appendix C, 4.11 and 4.12 of [<a href="https://arxiv.org/pdf/1908.11358.pdf" title="On the power of multiple anonymous messages">2</a>] or alternatively my re-derivations of the <a href="../ShufflePrivacy/index.html">same</a>.</p>
<p>The proofs for Shuffle privacy works out because the binomial distribution <span class="math inline">\((\epsilon, \delta, k)\)</span>-smooth and adding noise from a smooth distribution to the output of binary sums (which is a 1-incremental function) gives pure <span class="math inline">\(\epsilon\)</span> privacy with probality <span class="math inline">\(1 - \delta\)</span>. In general if the function being evaluated has sensitivity <span class="math inline">\(\Delta\)</span>, then we get <span class="math inline">\((\epsilon\Delta, \delta\Delta)\)</span> privacy but in our case <span class="math inline">\(\Delta=1\)</span>.</p>
<p>[<a href="https://arxiv.org/pdf/1908.11358.pdf" title="On the power of multiple anonymous messages">2</a>] define := distribution <span class="math inline">\(\mathbb{D}\)</span> is smooth over <span class="math inline">\(\mathbb{Z}\)</span> is <span class="math inline">\((\epsilon, \delta, k)\)</span> smooth, if <span class="math inline">\(\forall k&#39; \in [-k, k]\)</span> if the event E</p>
<p><span class="math display">\[\mathbb{P}_{Y \sim \mathbb{D}}\Big[E \geq e^{|k&#39;|\epsilon}\Big] \leq \delta\]</span> or</p>
<p><span class="math display">\[\mathbb{P}_{Y \sim \mathbb{D}}\Big[E &lt; e^{|k&#39;|\epsilon}\Big] &gt; 1 - \delta\]</span></p>
<p>where <span class="math display">\[E=\frac{\mathbb{P}_{Y&#39; \sim D}\Big[Y&#39;=Y\Big]}{\mathbb{P}_{Y&#39; \sim D}\Big[Y&#39;=Y+k&#39;\Big]}\]</span></p>
<p>To show that binomial is smooth we need event <span class="math inline">\(I(E \leq e^{|k&#39;|\epsilon})\)</span> happens with probability at least <span class="math inline">\(1 - \delta\)</span>. In the proofs Ghazi et al show that if event <span class="math inline">\(E_1\)</span> happens, then event <span class="math inline">\(I(E &gt; e^{|k&#39;|\epsilon})\)</span> happening is impossible i.e. <span class="math inline">\(E_1 =&gt; I(E \leq e^{|k&#39;|\epsilon})\)</span>.</p>
<p>Thus if event <span class="math inline">\(E_1\)</span> happens with probality at least 1 - <span class="math inline">\(\delta\)</span>, then so will event <span class="math inline">\(I(E \leq e^{|k&#39;|\epsilon})\)</span>. The event <span class="math inline">\(E_1\)</span> is defined as the sum of <span class="math inline">\(n\)</span> <span class="math inline">\(Bernoulli(p_1)\)</span> random variables be within a multiplicative factor of the mean of their expected sum. They can as the set of bernoulli random variables such that <span class="math inline">\(Z = (z_1, \dots, z_n)\)</span></p>
<p><span class="math display">\[E_1 := \{ Z | \sum_{i=1}^n z_i \in [(1 - \alpha)np_1 + k, (1 + \alpha)np_1 - k] \}\]</span> where <span class="math inline">\(\alpha \in (0,1)\)</span> and <span class="math inline">\(k=1\)</span> and <span class="math inline">\(z_i \sim Bernoulli(p_1)\)</span></p>
<p>The likelihood of this event <span class="math inline">\(E_1\)</span> can be bounded by the multiplicative chernoff bound. So the <span class="math inline">\(\delta\)</span> in shuffle privacy paper is pulled from the mulipilicative chernoff bound by setting the error region to</p>
<p><span class="math display">\[\tilde{E_1} := \{ Z | \sum_{i=1}^n z_i \in [(1 - \alpha/2)np_1 , (1 + \alpha/2)np_1 ]\}\]</span></p>
<p>By the two sides of the multiplicative chernoff bound we get</p>
<p>For <span class="math inline">\(\alpha &lt; 1\)</span>, we have <span class="math inline">\(\mathbb{P}[Z \notin \tilde{E_1}] \leq exp(-\frac{\alpha^2p_1 n}{8}) + exp(-\frac{\alpha^2p_1 n}{8+2\alpha}) &lt; exp(-\frac{\alpha^2p_1 n}{10}) + exp(-\frac{\alpha^2p_1 n}{10})\)</span></p>
<p>Setting <span class="math inline">\(\delta =2exp(-\frac{\alpha^2p_1 n}{10})\)</span>, and solving for <span class="math inline">\(p\)</span> we get what we need.</p>
<p>Since <span class="math inline">\(\tilde{E_1} \subseteq E_1\)</span>, if an event in <span class="math inline">\(\tilde{E_1}\)</span> happens with probability <span class="math inline">\(1 - \delta\)</span> then so will an event in <span class="math inline">\(E_1\)</span>.</p>
<p>The connection between the multiplicative factor <span class="math inline">\(\alpha\)</span> and the privacy parameter <span class="math inline">\(\epsilon\)</span> is <span class="math inline">\(\alpha = \frac{e^{\epsilon} - 1}{e^{\epsilon} + 1}\)</span>. Note: a constant greater than equal to <span class="math inline">\(\alpha\)</span> will only make the good event region bigger, so bounds that hold for <span class="math inline">\(\alpha = \frac{e^{\epsilon} - 1}{e^{\epsilon} + 1}\)</span> will also hold. This is how Balcer and Cheu get their bounds, in their shuffle privacy paper, Balcer and cheu show that setting <span class="math inline">\(\alpha = [\frac{\epsilon}{\sqrt{5}}, 1)\)</span>, is sufficient for the binomial distribution to be <span class="math inline">\((\epsilon, \delta, 1)\)</span> smooth. This is only true because <span class="math inline">\(\frac{\epsilon}{\sqrt{5}} \geq \frac{e^{\epsilon} - 1}{e^{\epsilon} + 1})\)</span> for all <span class="math inline">\(\epsilon \in [0,1]\)</span></p>
<p>and since binary sums are 1-incremental and have sensitivity <span class="math inline">\(\Delta=1\)</span>, we get <span class="math inline">\((\epsilon, \delta)\)</span> privacy for <span class="math inline">\(\alpha = [\frac{\epsilon}{\sqrt{5}}, 1)\)</span>.</p>
</div>
<div class="col-md-6">
<h4 id="sample-threshold">Sample-Threshold</h4>
<p>Now we look at the event <span class="math inline">\(E_2\)</span> that is needed for privacy to hold. From Grahams AI stats submission, lemma 1 defines <span class="math inline">\(E_2\)</span>. Lemma 1 states: the probability that the number of samples of an item is more than <span class="math inline">\(\tau\)</span> times its expectation is at most <span class="math inline">\(\delta\)</span>, for <span class="math inline">\(\tau = 3 + \log(1/\delta)\)</span>. In the world of just binary numbers, these requirements can be restated as the following:</p>
<p>Given the number of 1’s in the population is k. i.e. <span class="math inline">\(\sum_{i=1}^n x_i = k\)</span>. Each person <span class="math inline">\(x_i\)</span> has a <span class="math inline">\(p_2\)</span> chance of being sampled. Thus the expected number of 1’s in the sampled dataset is <span class="math inline">\(E[\sum_{i=1}^n z_ix_i] = kp_2=\frac{km}{n}\)</span></p>
<p>An element in the set of good events <span class="math inline">\(E_2\)</span> is defined as the sum of sampled population being less than <span class="math inline">\(\tau\)</span> times the expected value of the sum of the sampled population. Let <span class="math inline">\(\alpha = \frac{k}{n}\)</span> the fraction of users that have 1 in the dataset. Clearly, <span class="math inline">\(\alpha \in [0,1]\)</span></p>
<p><span class="math display">\[E_2: = \sum_{i=1}^n z_ix_i \leq \tau kp_2\]</span> Now we connect this event to the event <span class="math inline">\(E_1\)</span> in shuffle privacy.</p>
<p><span class="math display">\[\begin{align*}
\sum_{i=1}^n z_ix_i &amp;\leq \tau kp_2 \\
n - \sum_{i=1}^n \bar{z_ix_i} &amp;\leq \tau kp_2 \\
n - (2n - \sum_{i=1}^n x_i - \sum_{i=1}^n z_i) &amp;\leq \tau kp_2 \\
\sum_{i=1}^n z_i &amp;\leq \tau kp_2 + (n - \sum_{i=1}^n x_i) \\
\sum_{i=1}^n z_i &amp;\leq \tau kp_2 + (n - k) \\
\sum_{i=1}^n z_i &amp;\leq \tau \frac{k}{n} np_2 + (n - k) \\
\sum_{i=1}^n z_i &amp;\leq \tau \alpha np_2 + (n - k) \\
\end{align*}\]</span></p>
<p><span class="math display">\[E_2 := \{ (z_1,  \dots, z_n) | \sum_{i=1}^n z_i \in [0, \tau\alpha np_1 +(n -k)] \}\]</span></p>
<p>Already <span class="math inline">\(E_2\)</span> looks the one sided version of <span class="math inline">\(E_1\)</span>, with the constants slightly different. Let’s see if we can maniuplate them further.</p>
<div class="intuition">
The one sided vs two sided is not a big deal. It’s just the constant in the log factor. What can I do to relate the variables in the two events better?
</div>
<div class="question">
If I use two sided instead of 1 sided bounds – does Grahams proof still hold.
</div>
</div>
</div>
<h1 id="references">References</h1>
<ol type="1">
<li><a href="https://arxiv.org/pdf/2109.13158.pdf">Differentially Private Aggregation in the Shuffle Model: Almost Central Accuracy in Almost a Single Message</a></li>
</ol>
<ol start="2" type="1">
<li><a href="https://arxiv.org/pdf/1908.11358.pdf">On the power of multiple anonymous messages</a></li>
</ol>
</div>
<div id="footer">
  “Study hard what interests you the most in the most undisciplined, irreverent and original manner possible.”― Richard Feynmann
</div>
</body>
</html>
