<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>main</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="../blog.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
  
  <ul class="navbar">
    <h2><a class="active" href="/index.html">Notes on Differential Privacy</a></h2>
  </ul>
</head>
<body>
<div class="container">
<h1 id="separting-local-and-shuffle-privacy">Separting local and Shuffle Privacy</h1>
<h2 id="background-material">Background Material</h2>
<p>This is material that we need to be able to derive the proofs in the paper. <a href="https://arxiv.org/pdf/1908.11358.pdf" title="On the power of multiple anonymous messages">1</a> Identify a class of distributions and argue that, if <span class="math inline">\(\eta\)</span> is sampled from such a distribution, adding η to a 1-sensitive sum ensures differential privacy of that sum.</p>
<p>1-sensitive sums show up with computing sums on histograms with elements 1 or 0 on two datasets that differ by one record only.</p>
<h3 id="definition-smooth">Smooth Distributions</h3>
<p>A distribution <span class="math inline">\(\mathbb{D}\)</span> is smooth over <span class="math inline">\(\mathbb{Z}\)</span> is <span class="math inline">\((\epsilon, \delta, k)\)</span> smooth, if <span class="math inline">\(\forall k&#39; \in [-k, k]\)</span> if the event E</p>
<p><span class="math display">\[\mathbb{P}_{Y \sim \mathbb{D}}\Big[E \geq e^{|k&#39;|\epsilon}\Big] \leq \delta\]</span> or</p>
<p><span class="math display">\[\mathbb{P}_{Y \sim \mathbb{D}}\Big[E &lt; e^{|k&#39;|\epsilon}\Big] &gt; 1 - \delta\]</span></p>
<p>The second equation looks a lot like a concentration inequality i.e. it is saying that the value of the event being concentrated within the window is quite high.</p>
<p>This already looks a lot like Differential Privacy, which says, for DP to hold the ratio of the probabilities of a function outputting the same value on neigbhouring datasets is bounded by an exponential function as shown above with probability 1 - <span class="math inline">\(\delta\)</span></p>
<p>The Event <span class="math inline">\(E\)</span> is defined as the following</p>
<p><span class="math display">\[E=\frac{\mathbb{P}_{Y&#39; \sim D}\Big[Y&#39;=Y\Big]}{\mathbb{P}_{Y&#39; \sim D}\Big[Y&#39;=Y+k&#39;\Big]}\]</span></p>
<p>It’s saying if I draw a random variable from <span class="math inline">\(Y \sim \mathbb{D}\)</span>; the probability of drawing another variable <span class="math inline">\(Y&#39; \sim \mathbb{D}\)</span> within a window of [Y, Y+k’] is quite close to the original probability of drawing <span class="math inline">\(Y\)</span> to begin with.</p>
<!-- [Heading IDs](#custom-id)
-->
<h3 id="lemma-smooth">Lemma: Adding Noise from smooth distributions is a DP mechanism</h3>
<p>Let <span class="math inline">\(f: \mathbb{Z}^n \rightarrow \mathbb{Z}\)</span> be a function such that it is 1 sensitive i.e. <span class="math inline">\(|f(x) - f(x&#39;)| \leq 1\)</span> ffor all <span class="math inline">\(x \sim x&#39;\)</span>. Let <span class="math inline">\(\mathbb{D}\)</span> be a (, , 1) smooth distribution. Then the algorithm that takes <span class="math inline">\(x \sim \mathbb{Z}^n\)</span>, and outputs <span class="math inline">\(f(x) + \eta\)</span> where <span class="math inline">\(\eta \sim D\)</span> is DP.</p>
<h3 id="lemma-the-binomial-distribution-is-smooth">Lemma: The binomial distribution is smooth</h3>
<p>To show in a minute</p>
<h2 id="introduction">Introduction</h2>
<p>There has been a lot of work on local privacy. See here <strong>TODO</strong>. A new paradigm of privacy is shuffle privacy. In this paper, the authors try and understand the guarantees of shuffle privacy with respect to local privacy for the histogram sum estimation problem. There are two major findings:</p>
<ol type="1">
<li>The authors present a protocol in the shuffled model that estimates histograms with error independent of the domain size. This implies an arbitrarily large gap in sample complexity between the shuffled and local models. <strong>So all known local models depend on domain size</strong></li>
<li>Local and shuffle privacy are equivalent when we impose the constraints of pure differential privacy and single-message randomizers.</li>
</ol>
<h2 id="a-simplified-histogram">A simplified histogram</h2>
<p>Before estimating all histograms, the authors look at the binary histogram or binary sums where the cells of the histogram are constrained to have values in <span class="math inline">\(\{0, 1\}\)</span>.</p>
<p><strong>PUT PICTURE</strong></p>
<h3 id="an-algorithm-for-binary-sums-that-satisfies-shuffle-privacy">An algorithm for binary sums that satisfies shuffle privacy</h3>
<div class="algorithm">
<p><strong>RANDOMISER:</strong> <span class="math inline">\(\textit{R}_{\epsilon, \delta}^{zsum}\)</span></p>
<p>Input:</p>
<ul>
<li><span class="math inline">\(x \in \{0,1\}\)</span></li>
<li><span class="math inline">\((\epsilon, \delta) \in [0,1]\)</span></li>
</ul>
<p>Method:</p>
<ol type="1">
<li><span class="math inline">\(1 - p = \frac{50}{\epsilon^2 n}\log(\frac{2}{\delta})\)</span></li>
<li><span class="math inline">\(z \sim Bernoulli(p)\)</span></li>
</ol>
<p>Output:</p>
<ol start="3" type="1">
<li>Output x+z copies of 1s (At the most 2 bits)</li>
</ol>
<p><strong>ANANLYSER: </strong><span class="math inline">\(\textit{R}_{\epsilon, \delta}^{zsum}\)</span></p>
<p>Input:</p>
<ul>
<li><span class="math inline">\(n\)</span> outputs of <span class="math inline">\(\textit{R}_{\epsilon, \delta}^{zsum}\)</span>: which is a steam of 1’s i.e <span class="math inline">\(y \in \{ 1\}^*\)</span></li>
<li><span class="math inline">\((\epsilon, \delta) \in [0,1]\)</span></li>
</ul>
<p>Method:</p>
<ol type="1">
<li><span class="math inline">\(1 - p = \frac{50}{\epsilon^2 n}\log(\frac{2}{\delta})\)</span></li>
<li><span class="math inline">\(c* = \frac{1}{n}|y|\)</span> where |.| is the length of a stream</li>
</ol>
<p>Output:</p>
<ol start="3" type="1">
<li>if c* &gt; 1 : return (c* - p) else: return 0</li>
</ol>
</div>
<h3 id="theorem-binHistDP">Theorem: The above proptocol is DP for the shuffled model</h3>
<p>For any <span class="math inline">\(\epsilon, \delta \in [0,1]\)</span> and any <span class="math inline">\(n \in \mathbb{N}\)</span> such that <span class="math inline">\(n \geq \frac{100}{\epsilon^2}\log(\frac{2}{\delta})\)</span>, the protocol <span class="math inline">\((\textit{P}_{\epsilon, \delta}^{zsum}= \textit{R}_{\epsilon, \delta}^{zsum}, \textit{A}_{\epsilon, \delta}^{zsum})\)</span> has the following properties:</p>
<ol type="1">
<li><p><span class="math inline">\(\textit{P}_{\epsilon, \delta}^{zsum}\)</span> is <span class="math inline">\((\epsilon, \delta)\)</span>-differentially private in the shuffled model.</p></li>
<li><p>For <span class="math inline">\(\beta &gt; \delta^25\)</span>, the error <span class="math inline">\(|\textit{P}_{\epsilon, \delta}^{zsum}(X) - \frac{1}{n}\sum_{i=1}^n x_i| \leq \alpha\)</span> with probability <span class="math inline">\(1 - \beta\)</span></p></li>
<li>If <span class="math inline">\(X=(0,...0)\)</span>, then <span class="math inline">\(PBinHist(X)=0\)</span> i.e. we have 0 error.
<div class="question">

</div></li>
</ol>
<button type="button" class="btn btn-info" data-toggle="collapse" data-target="#binHistProof">
Proof
</button>
<div id="binHistProof" class="collapse">
<p>We are ready to show things</p>
</div>
<h2 id="histogram-summing-the-full-version">Histogram summing the full version</h2>
<h3 id="theorem-HistDP">Theorem: The above proptocol is DP for the shuffled model</h3>
<button type="button" class="btn btn-info" data-toggle="collapse" data-target="#histProof">
Proof
</button>
<div id="histProof" class="collapse">
<p>We are ready to show things</p>
</div>
<h1 id="privacy-definitions-cheat-sheet">Privacy definitions cheat sheet</h1>
<h2 id="definition-centralDP">Central Differential Privacy</h2>
<p>An algorithm <span class="math inline">\(M : X^n \rightarrow Z\)</span> satisfies <span class="math inline">\((\epsilon,\delta)\)</span>-differential privacy if</p>
<p><span class="math display">\[ \mathbb{P}_{x \sim X^n}\Big[M(x) \in T\Big] \leq e^{\epsilon}\mathbb{P}_{x&#39; \sim X^n}\Big[M(x&#39;) \in T\Big] + \delta\]</span></p>
<p><span class="math inline">\(\forall x \sim x&#39;\)</span> and <span class="math inline">\(\forall T \subseteq Z\)</span>. Two datasets are <span class="math inline">\(x \sim x&#39;\)</span> if they differ by one row or record. Note: For DP to apply, the above in equality must hold for <strong>all</strong> subsets of the range of the alorithm. Another way of viewing the above inequality is in terms of concentration measures:</p>
<p>With probablity 1 - <span class="math inline">\(\delta\)</span>.</p>
<p><span class="math display">\[ \frac{ \mathbb{P}_{x \sim X^n}\Big[M(x) \in T\Big]}{ \mathbb{P}_{x&#39; \sim X^n}\Big[M(x&#39;) \in T\Big]} \leq e^{\epsilon}\]</span></p>
<p>Usually <span class="math inline">\(\delta = o(1/n)\)</span> is accepted as workable or efficient. This is saying if datasets are neighbouring, central DP gurantees that the algorithm outputs are concentrated near each other with high probability.</p>
<h2 id="definition-localModel">Local Models</h2>
<p>First introduced in [<a href="https://arxiv.org/pdf/0803.0924.pdf" title="What can we learn privately">2</a>]</p>
<p>A protocol P in the (non-interactive) local model consists of two randomized algorithms:</p>
<ul>
<li>A randomiser <span class="math inline">\(\textit{R}: X \rightarrow Y\)</span> that takes as input a single user’s data and outputs a message.</li>
<li>An analyser <span class="math inline">\(\textit{A}: Y^* \rightarrow Z\)</span> that takes as input all user messages and computes the output of the protocol.</li>
</ul>
<p>We denote the protocol <span class="math inline">\(\textit{P} = (\textit{R}, \textit{A})\)</span>. We assume that the number of users n is public and available to both <span class="math inline">\(\textit{R}\)</span> and <span class="math inline">\(\textit{A}\)</span>. <span class="math inline">\(Let ⃗x \in X^n\)</span>. The evaluation of the protocol  on input ⃗x is</p>
<p><span class="math display">\[P(x) = (A \circ R)(x) = A\Big(R(x_1), \dots, R(x_n)\Big)\]</span></p>
<h2 id="definition-localDP">Local Differential Privacy</h2>
<p>A local protocol <span class="math inline">\(\textit{P} = (\textit{R}, \textit{A})\)</span> satisfies <span class="math inline">\((\epsilon, \delta)\)</span>-differential privacy for n users if its randomizer <span class="math inline">\(R : X \rightarrow Y\)</span> is <span class="math inline">\((\epsilon, \delta)\)</span>-differentially private (for datasets of size one). In other words, the output of the randomiser for any two inputs must be concentrated with high probability 1 - <span class="math inline">\(\delta\)</span></p>
<p><span class="math display">\[ \frac{ \mathbb{P}_{x \sim X}\Big[R(x) \in T\Big]}{ \mathbb{P}_{x&#39; \sim X}\Big[R(x&#39;) \in T\Big]} \leq
e^{\epsilon}\]</span> for all subsets <span class="math inline">\(T \subseteq Y\)</span></p>
<h2 id="definition-shuffleModel">Shuffled Model</h2>
<p>A protocol <span class="math inline">\(P\)</span> in the shuffled model consists of three randomized algorithms. The first and last algorithm is identical to the local model. There is a middle shuffle phase. Formally,</p>
<ul>
<li>A randomiser <span class="math inline">\(\textit{R}: X \rightarrow Y\)</span> that takes as input a single user’s data and outputs a message.</li>
<li>A shuffler <span class="math inline">\(S : Y^* \rightarrow Y^*\)</span>. that concatenates all message vectors and then applies a uniformly random permutation to (the order of) the concatenated vector. For example, when there are three users each sending two messages, there are 6! permutations and all are equally likely to be the output of the shuffler.<strong>NOTE: There is no special shuffling algorithm. It’s always uniformly random on all permutations</strong></li>
<li>An analyser <span class="math inline">\(\textit{A}: Y^* \rightarrow Z\)</span> that takes as input the shuffled messages and computes the output of the protocol.</li>
</ul>
<p>The evaluation of the protocol <span class="math inline">\(P=(R,A)\)</span> on input <span class="math inline">\(x\)</span> is</p>
<p><span class="math display">\[P(x) = (A \circ S \circ R)(x) = A\Big(S\big[R(x_1), \dots, R(x_n)\big]\Big)\]</span></p>
<h2 id="definition-shuffleDP">Shuffle Privacy</h2>
<p>A shuffled protocol <span class="math inline">\(P = (R,A)\)</span> satisfies <span class="math inline">\((\epsilon, \delta)\)</span>-differential privacy for <span class="math inline">\(n\)</span> users if the algorithm <span class="math inline">\((S \circ R) : X^n \rightarrow Y^∗\)</span> is <span class="math inline">\((\epsilon, \delta)\)</span>-differentially private.</p>
<p>This is saying, for two neighbouring datasets <span class="math inline">\(x \sim x&#39;\)</span>, the probability of seeing the same permutation after shuffling the outputs of all the local randomisers is concentrated with high probability 1 - <span class="math inline">\(\delta\)</span>.</p>
<p>The hope is the following: Because we have this shuffle phase, perhaps we can add a little less noise to the local randomisers thereby getting a little bit more accuracy.</p>
<h2 id="important-papers">Important Papers</h2>
<ol type="1">
<li><a href="https://arxiv.org/pdf/1908.11358.pdf">On the power of multiple anonymous messages</a></li>
</ol>
<ol start="2" type="1">
<li><a href="https://arxiv.org/pdf/0803.0924.pdf">What can we learn privately</a></li>
</ol>
</div>
<div id="footer">
   Copyright something something - what people usually right
</div>
</body>
</html>
