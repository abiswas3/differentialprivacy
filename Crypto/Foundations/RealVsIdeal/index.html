<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Security Defintions</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="../../crypto.css">
  <script src="../../../code/es5/tex-chtml.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <link rel="stylesheet" href="/code/bootstrap.min.css">
  <script src="/code/jquery.min.js"></script>
  <script src="/code/bootstrap.min.js"></script>
  
  
  <ul class="bar">
    <li class="barli"><a class="active" href="/">Home</a></li>
    <li class="barli"><a href="/differentialprivacy/index.html">My Notes</a></li>  
    <li class="barli"><a href="./..">Back</a></li>  
    <!-- <li class="barli"><a href="https://abiswas3.github.io/differentialprivacy.github.io">Notes on Differential Privacy</a></li> -->
  </ul>
</head>
<body>

<div class="container">
<<<<<<< HEAD
<p><strong>EDIT: Want to change this document to examples of proving
protocols are secure</strong></p>
<h1 id="semi-honest-adversaries">Semi honest adversaries</h1>
<p>Given input and and output, can generate the adversaries view of the
protocol execution. <strong>IMPORTANT: </strong> Since all parties
follow the protocol, the inputs are well defined. Go back to the ideal
world, where <span class="math inline">\(f_{Ideal}\)</span> receives
inputs and outputs the answer. The adversary can see only the
input/output of the corrupted parties and the final output and
<em>nothing else</em>. He has to attack this world. This adversary is
the simulator. We have to show that the simulators view is
indistinguishable from that of the real world adversary.</p>
<p><img src="pngs/semi_honest.png" width="90%"></img></p>
<p>The joint distribution of left and the joint distribution of the
right has to look the same. <strong>WHY JOINT ?</strong></p>
<p>In semi-honest : correctness, independence of inputs and fairness are
non issues because everyone has to follow the protocols.</p>
<p><strong>OLD</strong></p>
<h1 id="security-models-for-multi-party-computation-mpc">Security Models
for Multi Party Computation (MPC)</h1>
=======
<h1 id="security-models-for-multi-party-computation-mpc">Security Models for Multi Party Computation (MPC)</h1>
>>>>>>> 3bb8c76905e0e327291ce3c86b3aaa28cc734590
<h2 id="secret-sharing">Secret Sharing</h2>
<p>Informally, <span class="math inline">\((t,n)\)</span> secret sharing is method by which we split a secret <span class="math inline">\(s\)</span> into <span class="math inline">\(n\)</span> shares such that only <span class="math inline">\(t\)</span> shares are needed to re-construct the secret. Additionally, any combination of <span class="math inline">\(t-1\)</span> shares reveals no information about <span class="math inline">\(s\)</span>. More formally, it is a pair of algorithms <span class="math inline">\((Shr, Rec)\)</span> that satisfies the following two properties:</p>
<div class="theorem">
<ul>
<li><p>Correctness: Let <span class="math inline">\(Shr(s) = (s_1, \dots, s_n)\)</span>, for <span class="math inline">\(s \in D\)</span> where <span class="math inline">\(D\)</span> is the domain of secrets, then <span class="math inline">\(\forall k \geq t\)</span>, we have <span class="math inline">\(\mathbb{P}\Big[ Rec(s_{i1}, \dots, s_{ik} = s\Big] = 1\)</span></p></li>
<li>Perfect Privacy: Let <span class="math inline">\(a, b \in D\)</span> and <span class="math inline">\(Shr(a)|_{k}\)</span> be the projection of the shares <span class="math inline">\((a_1, \dots, a_n)\)</span> onto a subspace <span class="math inline">\(D^k\)</span> for <span class="math inline">\(k &lt; t\)</span>. Let <span class="math inline">\(v=(v_1, \dots, v_k) \in D^k\)</span>, then we have <span class="math display">\[\begin{align*}
\mathbb{P}\Big[ Shr(a)|_{k} = v\Big] &amp;= \mathbb{P}\Big[ Shr(b)|_{k} = v\Big] 
\end{align*}\]</span></li>
</ul>
</div>
<p>In other words,<span class="math inline">\(Shr(a)|_{k}\)</span> and <span class="math inline">\(Shr(b)|_{k}\)</span> are perfectly indistinguishable. Colloquially we can say that by looking at any <span class="math inline">\(v\)</span> as defined above, it is impossible to gain any information about the secret : as all values in the domain <span class="math inline">\(D\)</span> are equally likely to be the secret. The best anyone can do is guess uniformly at random.</p>
<h3 id="examples">Examples</h3>
<p>Additive secret sharing and Shamirs secret sharing.</p>
<h2 id="what-is-mpc">What is MPC ?</h2>
<p>Intuitive explanation</p>
<h2 id="what-does-it-mean-for-a-mpc-to-be-secure">What does it mean for a MPC to be secure?</h2>
<p>One way to do it would be to enumerate all the properties that we would classify as a violation of security. <code>For example, the adversary should not be able to learn a certain predicate of another party’s input, the adversary should not be able to induce impossible outputs for the honest parties, and the adversary should not be able to make its inputs depend on honest parties’ inputs. Not only is this a tedious approach, but it is cumbersome and error-prone. It is not obvious when the laundry list could be considered complete.</code>– [<a href="http://securecomputation.org/docs/pragmaticmpc.pdf" title="A Pragmatic Introduction to Secure Multi-Party Computation">1</a>]</p>
<p>Alternatively, we could define a perfect/ideal world which has all the nice properties we desire and compare a protocol against this world.</p>
<h3 id="ideal-world">Ideal World</h3>
<p>In an ideal world, the parties want to compute a function <span class="math inline">\(\mathcal{F}\)</span> by sending their private inputs to some trusted incorruptible party <span class="math inline">\(\mathcal{T}\)</span>. Party <span class="math inline">\(P_i\)</span> has input <span class="math inline">\(x_i\)</span>, which is sent to <span class="math inline">\(\mathcal{T}\)</span> who outputs <span class="math inline">\(\mathcal{F}(x_1, \dots, x_n)\)</span>. Consider an adversary attacking the ideal world. We call such an adversary the simulator. This simulator is able to take over any parties <span class="math inline">\(P_i\)</span> but not <span class="math inline">\(\mathcal{T}\)</span>. Therefore, all the simulator is able to view, is their input <span class="math inline">\(x_i\)</span> and the final output <span class="math inline">\(\mathcal{F}(x_1,\dots, x_n)\)</span>. Thus it must choose their evil inputs, independent of the input of the honest parties.</p>
<h3 id="real-world">Real World</h3>
<p>In the real world there are no trusted third parties. Instead all parties communicate with each other using a protocol <span class="math inline">\(\pi\)</span>. The protocol <span class="math inline">\(\pi\)</span> specifies for each party <span class="math inline">\(P_i\)</span>, the next message function <span class="math inline">\(\pi_i\)</span> – which takes as input the input <span class="math inline">\(x_i\)</span>, the bits of Party <span class="math inline">\(i\)</span>’s random tape <span class="math inline">\(r_i\)</span> and all the messages it has received so far. Then <span class="math inline">\(\pi_i\)</span> outputs either a next message to send along with its destination, or else instructs the party to terminate with some specific output. In the real world, an adversary can corrupt parties—corruption at the beginning of the protocol is equivalent to the original party being an adversary. How they can corrupt parties depends on the trust models described below.</p>
<div class="important">
<strong>Intuition</strong> A protocol <span class="math inline">\(\pi\)</span> is secure if any effect that an adversary can achieve in the real world can also be achieved by a corresponding adversary in the ideal world
</div>
<p><code>Note: This simulator paradigm is almost identical to the Zero Knowledge proofs for interactive proofs</code></p>
<h2 id="trust-models">Trust Models</h2>
<h3 id="passive-security-honest-but-curious-adversaries-semi-honest-adversary">Passive Security / Honest but curious adversaries / Semi Honest adversary</h3>
<p>All 3 names refer to the same model.</p>
<p>A semi-honest adversary is one who corrupts parties but follows the protocol as specified. The corrupt parties run the protocol honestly but they may try to learn as much as possible from the messages they receive from other parties. An adversary may collude with multiple parties, and in that case, the view of the adversary is the combined view of each of the corrupted parties.</p>
<p>The view of a party in the semi honest model is the following:</p>
<ul>
<li>The honest input <span class="math inline">\(x_i\)</span></li>
<li>Their random tape <span class="math inline">\(r_i\)</span></li>
<li>All messages received <span class="math inline">\(z_1, \dots, z_m\)</span></li>
</ul>
<p>The view of an adversary is the combined view of all the parties they have corrupted. An attack is anything any efficient (PPT) algorithm can compute using this view. Thus an attack is equivalent to just releasing the view to the public world.</p>
<div class="important">
<strong>Intuition</strong> The protocol is secure if the view generated by the simulator is computationally indistinguishable from the actual adversaries view. Note: The simulator only access has access to the honest inputs of the corrupt parties and the final output of the protocol. Showing that such a simulator exists proves that there is nothing an adversary can accomplish in the real world that could not also be done in the ideal world. <strong>So whenever we want to show something is secure, the game will always be to write down a simulator that has the above properties</strong>
</div>
<p>Formal defintion:</p>
<div class="theorem">
<p>More formally, let <span class="math inline">\(\pi\)</span> be a protocol and <span class="math inline">\(\mathcal{F}\)</span> be a functionality. Let <span class="math inline">\(C\)</span> be the set of parties that are corrupted, and let <span class="math inline">\(Sim\)</span> denote a simulator algorithm. We define the following distributions of random variables:</p>
<ol type="1">
<li>Let <span class="math inline">\(Real_{\pi}(\kappa, C, x_1, \dots, x_n)\)</span> output the ensemble of random variables :
<ul>
<li><span class="math inline">\(\{V_i: i \in C\}\)</span>: The view of the corrupt parties</li>
<li><span class="math inline">\(y_1, \dots, y_n\)</span> : The ouput of the each party</li>
</ul>
<p>by running protocol <span class="math inline">\(\pi\)</span> with security parameter <span class="math inline">\(\kappa\)</span>, where each party <span class="math inline">\(P_i\)</span> acts honestly using following <span class="math inline">\(\pi_i\)</span>. Let <span class="math inline">\(V_i\)</span> be the view of party <span class="math inline">\(P_i\)</span> and <span class="math inline">\(y_i\)</span> be the output of the same party.</p></li>
<li>Let <span class="math inline">\(Ideal_{\mathcal{F}, Sim}(\kappa, C, x_1, \dots, x_n)\)</span> output of ensemble of random variables:
<ul>
<li><span class="math inline">\(y_1, \dots, y_n\)</span> : The ouput of the each party</li>
<li><span class="math inline">\(Sim(C, \{ (x_i, y_i): i \in C\})\)</span>: The view of the corrupt adversary in the ideal model</li>
</ul></li>
</ol>
<p>We say, A protocol <span class="math inline">\(\pi\)</span> securely realizes <span class="math inline">\(\mathcal{F}\)</span> in the presence of semi-honest adversaries if there exists a simulator <span class="math inline">\(Sim\)</span> such that, for every subset of corrupt parties <span class="math inline">\(C\)</span>, <span class="math inline">\(Ideal_{\mathcal{F}, Sim}(\kappa, C, x_1, \dots, x_n)\)</span> and <span class="math inline">\(Real_{\pi}(\kappa, C, x_1, \dots, x_n)\)</span> are computationally indistinguishable in terms of <span class="math inline">\(\kappa\)</span>.</p>
</div>
<p><strong>NOTE:</strong> The defintion includes all the outputs, even those of the honest parties. This is done to enforce correctness, in the case $<span class="math inline">\(C=\emptyset\)</span>. Then we require that the output in the ideal model be indistinguishable from the real model. If <span class="math inline">\(\mathcal{F}\)</span> is deterministic, this implies correctness. Also note that in the case of passive security, we could just focus on the Views. As no party can deviate from the protocol, we are always guaranteed correctness if <span class="math inline">\(\pi\)</span> is propertly designed.</p>
<h3 id="malicious-security">Malicious Security</h3>
<p>A malicious (also known as active) adversary may instead cause corrupted parties to deviate arbitrarily from the prescribed protocol in an attempt to violate security. A malicious adversary has all the powers of a semi-honest one in analyzing the protocol execution, but may also take any actions it wants during protocol execution. Now there are two things to consider:</p>
<ul>
<li><p>Effect on honest outputs: Because this active adversary can send in bad inputs the output of the honest parties might be affected. So when we analyse active security, we must make claims about honest outputs. Systems like Poplar and Prio ignore robustness of output in presence of active adversaries.</p></li>
<li><p>Extraction: Earlier we could not change input to <span class="math inline">\(\mathcal{T}\)</span> even for corrupted parties. In contrast, the input of a malicious party is not well-defined in the real world, which leads to the question of what input should be given to <span class="math inline">\(\mathcal{T}\)</span> in the ideal world. The answer is we let the ideal world adversary i.e. the simulator also pick the inputs as it wants. <strong>This aspect of simulation is called extraction, since the simulator extracts an effective ideal-world input from the real-world adversary that “explains” the input’s real-world effect.</strong></p></li>
</ul>
<div class="theorem">
<p>When <span class="math inline">\(A\)</span> denotes the adversary program, we write <span class="math inline">\(corrupt(A)\)</span> to denote the set of parties that are corrupted, and use <span class="math inline">\(corrupt(Sim)\)</span> for the set of parties that are corrupted by the ideal adversary, <span class="math inline">\(Sim\)</span>.</p>
<ol type="1">
<li>Let <span class="math inline">\(Real_{\pi, A}(\kappa, x_i \notin corrupt(A))\)</span> output the ensemble:
<ul>
<li><span class="math inline">\(\{y_i: i \notin corrupt(A)\}\)</span> *<span class="math inline">\(\{V_i: i \in corrupt(A)\}\)</span></li>
</ul>
<p>by running <span class="math inline">\(\pi\)</span> on the honest inputs and messages of clients and malicious inputs and messages selected by <span class="math inline">\(A\)</span>. <span class="math inline">\(V_i\)</span> is the view of party <span class="math inline">\(P_i\)</span>.</p></li>
<li>Let <span class="math inline">\(Ideal_{\mathcal{F}, Sim}(\kappa, x_i \notin corrupt(A))\)</span> first generate <span class="math inline">\(x_i \in corrupt(A)\)</span>, then run <span class="math inline">\((y_1, \dots, y_n) = \mathcal{F}(x_1, \dots, x_n).\)</span> Then give <span class="math inline">\(\{y_i: i \in corrupt(A)\}\)</span> to Sim to get the final view set of simulated views. We then output the ensemble
<ul>
<li><span class="math inline">\(V^*\)</span>: This is the view of the corrupt parties plus the corrupt outputs.</li>
<li><span class="math inline">\(\{y_i: i \notin corrupt(Sim)\}\)</span></li>
</ul></li>
</ol>
<p>We say, A protocol <span class="math inline">\(\pi\)</span> securely realizes <span class="math inline">\(\mathcal{F}\)</span> in the presence of active adversaries if there exists a simulator <span class="math inline">\(Sim\)</span> such that, <span class="math inline">\(corrupt(Sim) = corrupt(A)\)</span>, and for all honest party inputs, <span class="math inline">\(Ideal_{\mathcal{F}, Sim}(\kappa, x_i \notin corrupt(A))\)</span> and <span class="math inline">\(Real_{\pi, A}(\kappa, x_i \notin corrupt(A))\)</span> are computationally indistinguishable in terms of <span class="math inline">\(\kappa\)</span>.</p>
</div>
<h3 id="security-with-abort">Security with Abort</h3>
<p>In any real world protocol, one party receives its output before the other. If the first party is evil they can abort and not give the honest client any output at all. Thus our defintions won’t hold as we require the outputs of honest parties be indistinguishable in the ideal world and real world. The ideal world has no such issue of deadlocks. To work around this, there is a weaker notion of security which modifies the ideal <span class="math inline">\(\mathcal{F}\)</span> as follows: In this model, the outputs are first given to evil parties who can then either deliver or abort. If they deliver things work as before, if they abort, the honest clients are sent a special symbol <span class="math inline">\(\bot\)</span>.</p>
<h2 id="examples-of-simulators">Examples of Simulators</h2>
<h3 id="poplar-with-at-least-1-honest-server">Poplar with at least 1 honest server</h3>
<p><img src="pngs/bad_server_sketch.png" width="95%"></img></p>
<h3 id="prio-with-at-least-1-honest-server">Prio with at least 1 honest server</h3>
<p>TODO</p>
<h1 id="references">References</h1>
<ol type="1">
<li><a href="http://securecomputation.org/docs/pragmaticmpc.pdf">A Pragmatic Introduction to Secure Multi-Party Computation</a></li>
</ol>
<ol start="2" type="1">
<li><a href="https://eprint.iacr.org/2004/175.pdf">A Proof of Security
of Yao’s Protocol for Two-Party Computation</a></li>
</ol>
</div>
<div id="footer">
  “Study hard what interests you the most in the most undisciplined, irreverent and original manner possible.”― Richard Feynmann
</div>
</body>
</html>
