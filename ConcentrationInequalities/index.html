<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Readme</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="../blog.css">
  <script src="../code/es5/tex-chtml.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <link rel="stylesheet" href="/code/bootstrap.min.css">
  <script src="/code/jquery.min.js"></script>
  <script src="/code/bootstrap.min.js"></script>
  
  
  <ul class="bar">
    <li class="barli"><a class="active" href="/">Home</a></li>
    <li class="barli"><a href="/differentialprivacy/index.html">Notes on Differential Privacy</a></li>  
    <!-- <li class="barli"><a href="https://abiswas3.github.io/differentialprivacy.github.io">Notes on Differential Privacy</a></li> -->
  </ul>
</head>
<body>

<div class="container">
<h1 id="concentration-inequalities">Concentration Inequalities</h1>
<p>Interested in tail bounds i.e. how random variables deviate from their means.</p>
<p><strong>Plot the different rates and show why one is better than the other</strong></p>
<h2 id="markovs-inequlity">Markovs inequlity</h2>
<p>The simplest tail bound that applies to any <strong>non negative random variable</strong> is the markov inequality.</p>
<p><span class="math display">\[\mathbb{P}_{X \sim D}\Big[X \geq a\Big] \leq \frac{\mathbb{E}[X]}{a}\]</span> <span class="math inline">\(\forall a &gt; 0\)</span> where <span class="math inline">\(D\)</span> is the distribution of the random variable.</p>
<button type="button" class="btn btn-info" data-toggle="collapse" data-target="#markovInEq">
Proof
</button>
<div id="markovInEq" class="collapse">
<p>Let <span class="math inline">\(X : S \rightarrow R^+\)</span> be a non-negative random variable</p>
<p>We can divide the set <span class="math inline">\(S = S_1 + S_2\)</span> where <span class="math inline">\(S_1 = \{ s | X(s) \geq a\}\)</span> and <span class="math inline">\(S_2 = \{ s | X(s) &lt; a\}\)</span></p>
<span class="math display">\[\begin{align*}
\mathbb{E}[X] &amp;= \int_{s \in S} X(s)f(s)ds \\
&amp;=\int_{s \in S_1} X(s)f(s)ds + \int_{s \in S_2} X(s)f(s)ds \\
\end{align*}\]</span>
<p>Since <span class="math inline">\(\int_{s \in S_2} X(s)f(s)ds \geq 0\)</span> as <span class="math inline">\(X(s) &gt; 0\)</span> <span class="math inline">\(\forall s \in S\)</span>, we have</p>
<span class="math display">\[\begin{align*}
\int_{s \in S_1} af(s)ds &amp;\leq \int_{s \in S_1} X(s)f(s)ds \\
&amp;\leq \mathbb{E}[X] \\
\int_{s \in S_1} f(s)ds &amp;\leq  \frac{\mathbb{E}[X]}{a}\\
\mathbb{P}[X \geq a]&amp;\leq \frac{\mathbb{E}[X]}{a} \\
\end{align*}\]</span>
</div>
<h2 id="chebyshevs-inequality">Chebyshevs inequality</h2>
<p>The next tail bound is for random variables from a slighlty more restrictive class. Variables who have their variances bounded. The only assumption the Markov inequality makes is that the random variable is non negative.</p>
<p><span class="math display">\[\mathbb{P}_{X \sim D}\Big[|X - \mu| \geq a\Big] \leq \frac{Var(X)}{a^2}\]</span></p>
<button type="button" class="btn btn-info" data-toggle="collapse" data-target="#Chebyshev">
Proof
</button>
<div id="Chebyshev" class="collapse">
<p>Let <span class="math inline">\(X\)</span> be a random variable where <span class="math inline">\(Var(X) = \sigma^2\)</span>. By Markov, for every <span class="math inline">\(a &gt; 0\)</span></p>
<span class="math display">\[\begin{align*}
\mathbb{P}[ (X - \mu)^2 \geq a^2] &amp;\leq \frac{\mathbb{E}[(X - \mu)^2]}{a^2} \\
&amp;= \frac{\sigma^2}{a^2}
\end{align*}\]</span>
<p>Note the event <span class="math inline">\(\mathbb{P}[|X - \mu| \geq a] = \mathbb{P}[(X - \mu)^2 \geq a^2]\)</span> thus we can conclude that</p>
<p><span class="math display">\[\mathbb{P}_{X \sim D}\Big[|X - \mu| \geq a\Big] \leq \frac{Var(X)}{a^2}\]</span></p>
</div>
<h2 id="weak-law-large-of-numbers">Weak Law Large of Numbers</h2>
<p>The Chebyshev inequality also gives us the weak law of large numbers under the same assumptions (the probability distribution must have finite variance). The weak law of large numbers states</p>
<p><span class="math display">\[\frac{1}{N}\sum_{i=1}^N X_i \xrightarrow[]{\text{P}} \mu\]</span> as <span class="math inline">\(N \rightarrow \infty\)</span> or in other words the same statement is equivalent to</p>
<p>For any <span class="math inline">\(\epsilon &gt; 0\)</span> <span class="math display">\[ \mathbb{P}[|\sum_{i=1}^N X_i - \mu| \geq \epsilon] = 0 \]</span> as <span class="math inline">\(N \rightarrow \infty\)</span></p>
<button type="button" class="btn btn-info" data-toggle="collapse" data-target="#WeakLawOfLarge">
Proof
</button>
<div id="WeakLawOfLarge" class="collapse">
<p>Pick <span class="math inline">\(a &gt; 0\)</span>, then</p>
<span class="math display">\[\begin{align*}
\mathbb{P}_{X_i \sim D}\Big[|1/N\sum_{i=1}^N X_i - \mu| \geq a\Big] &amp;\leq \frac{Var(1/N\sum_{i=1}^N X_i)}{a^2} \label{1}\tag{1} \\
&amp;= \frac{1}{N^2}Var(X_i)
\end{align*}\]</span>
<p>Clearly as <span class="math inline">\(N \rightarrow \infty\)</span>, the RHS goes to 0.</p>
<p><span class="math inline">\(\ref{1}\)</span> Using chebychev</p>
</div>
<h2 id="the-chernoff-bound">The Chernoff Bound</h2>
<p><strong>There are a million variants to the Chernoff bound:</strong>The Chernoff bound is like a genericized trademark: it refers not to a particular inequality, but rather a technique for obtaining exponentially decreasing bounds on tail probabilities.</p>
<h2 id="hoeffdings-bound">Hoeffdings Bound</h2>
<h2 id="useful-tricks">Useful tricks</h2>
<h3 id="bounding-bernoullis">Bounding Bernoullis</h3>
<h3 id="bounding-exponentials">Bounding exponentials</h3>
<h1 id="resources">Resources</h1>
<ul>
<li><a href="https://towardsdatascience.com/moment-generating-function-explained-27821a739035">How are moment Generating functions used</a></li>
<li><a href="https://math.dartmouth.edu/~m20x18/markov">Markov and Chebyshev</a></li>
<li><a href="">Chernoff Bounds</a></li>
</ul>
</div>
<div id="footer">
  “Study hard what interests you the most in the most undisciplined, irreverent and original manner possible.”― Richard Feynmann
</div>
</body>
</html>
