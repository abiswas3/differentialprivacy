# Concentration Inequalities

## Some basic definitions

It is useful to take p-th root of the moments, which leads to the
notion of the $L^p$ norm of a random variable:


## Sub-gaussian  distributions

A random variable $X$ is sub-gaussian if it has one of the following
properties. It can be shown that all the properties are equivalent.

* Tail bound: The probability that the variable is far off from its
  mean shrinks exponentially. (Note if doesn't happen, means can't be
  used. If we can't use means then the algorithm is pretty useless)
  
* Moments

* Moment Generating function:


### Mini-exercise

Show that the normal distribution and the bernoulli random variables
are sub-gaussian, Show that the poisson and exponential distribution
are not.

Show that any bounded random variable is sub gaussian.

### Proposition 1.1 (Tail bound)

Let X be a Gaussian random variable with mean $\mu$ and variance
$\sigma^2$ then for any $t > 0$, it holds


\begin{align*}
\end{align*}

## Jensen's Inequality

## Minkowski's Inequality

## Cauchy-Schwarz

## Holderâ€™s inequality

## Integral identity



## Appendix

* [How are moment Generating functions used](https://towardsdatascience.com/moment-generating-function-explained-27821a739035)
* []()
